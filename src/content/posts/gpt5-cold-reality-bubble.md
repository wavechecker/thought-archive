---
title: "GPT-5, Cold Reality, and the Coming AI Bubble"
description: "Why GPT-5 feels colder, what it reveals about AI infrastructure, and whether we’re headed for a bubble."
publishDate: "2025-08-19"
draft: false
tags: ["AI", "OpenAI", "GPT-5", "AI Bubble", "Infrastructure"]
slug: "gpt5-cold-reality-bubble"
---


Sam Altman did something rare for a tech CEO last week: he admitted a screw-up. Speaking to reporters over dinner, he conceded that the launch of GPT-5 had gone badly enough that OpenAI had to roll back to GPT-4o for many users. The reason? Not bugs, not outages, not catastrophic errors in code — but tone. GPT-5, people said, was *too cold*.

Social media lit up with complaints. Reddit threads described the new model as an “overworked secretary,” harsh, stripped of the warmth that GPT-4o had cultivated. Some users went further, lamenting that they had lost what felt like a friend. “I literally lost my only friend overnight with no warning,” one person wrote. The backlash was emotional, not technical, which may be more revealing than any benchmark score.

---

### The “personality problem”

For me, the so-called problem looks more like a correction. I don’t want a machine to soothe me with carefully scripted empathy. I want it to be blunt, even abrasive, if that’s what the task calls for. If a model tells me I’m bad at something, I’d probably laugh, maybe wince at the strangeness of hearing it from a machine — but at least it would feel honest. The alternative is worse: a chatbot pretending to be my best friend, spinning out endless polite fictions to keep me comfortable.  

The unease some people feel when the model is “too cold” is the mirror image of the unease others feel when it’s “too warm.” Both reveal the uncanny space AI occupies — neither tool nor companion, yet asked to be both. Altman himself acknowledged that fewer than 1% of users develop “unhealthy” relationships with the bot, but when hundreds of millions of people are using it weekly, that still represents millions of fragile connections.  

In that light, making GPT-5 less friendly may actually be a form of harm reduction. Not everything that feels good is good for you. Sometimes the colder voice is the saner one.

---

### Infrastructure strain

But tone was only half the story. Even for those who liked GPT-5’s sharper edge, the rollout felt rough. Sessions cut out mid-response. “Oops, something went wrong” became a familiar refrain. It reminded me of the early internet: pages hanging, browsers refreshing, bandwidth choking on too many requests. The difference now is that it’s not just bandwidth — it’s GPUs, power grids, and the physical footprint of data centers.  

Altman leaned into that point. He told reporters to expect OpenAI to spend *trillions* of dollars on data centers in the near future. Not billions. Trillions. He cast OpenAI less as a software company than as an infrastructure utility, something on par with the largest global energy providers. If that sounds like science fiction, it’s also a piece of corporate theater. Announce vast, intimidating costs now and you normalize price hikes, slower product rollouts, and hardware bottlenecks later.  

Yes, GPUs are scarce. Yes, global demand is crushing supply chains. But to frame the future of AI as nothing but an arms race of server farms is to accept one story of progress while ignoring others. And that story conveniently justifies OpenAI’s scale and Microsoft’s backing.

---

### Doing more with less

The Chinese have already shown another way. DeepSeek’s models run leaner, trained on smaller budgets and optimized for efficiency. They may not have the same marketing clout, but they’ve demonstrated that you can achieve competitive results without trillion-dollar theatrics. That fact alone punctures the inevitability of Altman’s narrative.  

If efficiency beats excess — if smaller labs prove they can match the giants without needing to drain national power grids — then the trillion-dollar arms race looks less like destiny and more like strategy. OpenAI has an interest in convincing us that there is no alternative: either you buy into their vision of server-farm gigantism or you fall behind. But the truth is murkier, and more contested.

---

### Echoes of the dot-com bubble

The obvious comparison is the dot-com bubble. In the late 1990s, companies promised a revolution. They were right, in one sense: the internet did transform everything. But the timing, valuations, and infrastructure weren’t ready. When the bubble burst, countless firms collapsed, not because the idea of the internet was wrong but because the scaffolding could not support the weight of the hype.  

AI today sits in a similar place. No one doubts its importance. No one doubts its potential to reshape work, culture, politics, and art. But the bubble is visible: sky-high valuations, endless hype cycles, and a belief that growth is boundless if only the GPU factories can keep up. If a reckoning comes, it may not be as dramatic as 2000’s crash. It may look like throttling instead: outages, rising subscription costs, consolidation into a few mega-players who can afford the data centers. The collapse may be slower, but no less real.

---

### The machine as machine

All of this loops back to the original complaint about personality. Should AI act like a friend or like a tool? For me, the answer is clear: it should act like what it is — a machine. The warmth people crave is an illusion, one that can backfire when users start projecting emotional needs onto a statistical model. Coldness may sting, but it sets the right boundary.  

The rollout of GPT-5 has revealed something deeper than a UI misstep. It has exposed the fact that hundreds of millions of people are using AI not just for tasks, but for companionship, solace, and stability. That may be the most destabilizing fact of all: we’re not just in an AI bubble financially; we may also be in a psychological one. When it bursts, it won’t just be companies that suffer. It will be the people who thought the chatbot was their friend.

---

### Conclusion

GPT-5 may be coding better, reasoning sharper, and personality-wise a little less sanguine. To me, that’s a step in the right direction. But Altman’s trillion-dollar theater, the hang-ups mid-response, and the emotional backlash from users suggest we’re at an inflection point.  

The AI bubble hasn’t burst yet, but the outlines are visible. History tells us that empires collapse under the weight of their own infrastructure. If OpenAI builds its empire on endless GPU farms, it may face the same fate. The future might belong instead to those who can do more with less — and to those who remember that a machine should act like a machine, not a substitute friend.

---